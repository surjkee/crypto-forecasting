# ui/tabs/debugging.py

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
import torch

from config.settings import get_settings
from data.db import load_ohlcv_hourly
from features.transform import build_feature_frame

from models.baseline import naive_constant_forecast
from models.lstm.inference import load_lstm_checkpoint
from models.lstm.train import _inverse_scale_target
from models.gru.inference import load_gru_checkpoint
from models.gru.config import GRUConfig


from ui.constants import TRACKED_COINS




def render_debugging_tab():
    settings = get_settings()
    vs_currency = settings.default_vs_currency

    st.markdown("""
<style>
        /* Remove blank space at top and bottom */ 
        .block-container {
            padding-top: 0rem;
            padding-bottom: 0rem;
        }
</style>
""", unsafe_allow_html=True)

    st.markdown(
    """
    <h1 style="text-align: center; margin-top: 0;">
        üõ† Debugging
    </h1>
    """,
    unsafe_allow_html=True
)
    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≥–ª–æ–±–∞–ª—å–Ω–æ –æ–±—Ä–∞–Ω—É –º–æ–Ω–µ—Ç—É + –ª–æ–∫–∞–ª—å–Ω–∏–π –≤–∏–±—ñ—Ä –º–æ–¥–µ–ª—ñ
    labels = [label for label, _ in TRACKED_COINS]
    ids = [cid for _, cid in TRACKED_COINS]
    default_index = ids.index("bitcoin") if "bitcoin" in ids else 0
    default_label = labels[default_index]
    default_id = ids[default_index]

    selected_coin_id = st.session_state.get("selected_coin_id", default_id)
    selected_label = st.session_state.get("selected_coin_label", default_label)


    model_choice = st.radio(
        "–ú–æ–¥–µ–ª—å:",
        options=["Baseline", "LSTM", "GRU"],
        horizontal=True,
        key="debug_model_choice",
    )

    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ –∑ DuckDB
    df_raw = load_ohlcv_hourly(selected_coin_id, vs_currency)

    if df_raw.empty:
        st.warning(
            "–£ –±–∞–∑—ñ –Ω–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è —Ü—ñ—î—ó –º–æ–Ω–µ—Ç–∏. "
            "–°–ø–æ—á–∞—Ç–∫—É –∑–∞–ø—É—Å—Ç–∏ job –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó:\n\n"
            "`python -m jobs.fetch_history`"
        )
        return

    # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ timestamps –¥–æ —Ü—ñ–ª–æ—ó –≥–æ–¥–∏–Ω–∏
    df_raw = df_raw.copy()
    df_raw["ts_hour"] = df_raw["ts"].dt.floor("h")

    # –û–¥–∏–Ω –∑–∞–ø–∏—Å –Ω–∞ –≥–æ–¥–∏–Ω—É
    df_hourly = (
        df_raw.sort_values("ts_hour")
        .drop_duplicates(subset=["ts_hour"], keep="last")
        .reset_index(drop=True)
    )

    if len(df_hourly) < 24 * 3:
        st.warning(
            "–ó–∞–º–∞–ª–æ –¥–∞–Ω–∏—Ö –¥–ª—è –∞–¥–µ–∫–≤–∞—Ç–Ω–æ–≥–æ backtest'—É (–ø–æ—Ç—Ä—ñ–±–Ω–æ —Ö–æ—á–∞ –± 3 –¥–Ω—ñ "
            "–∑ –ø–æ–≥–æ–¥–∏–Ω–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏). –°–ø—Ä–æ–±—É–π –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –±—ñ–ª—å—à–∏–π —ñ–Ω—Ç–µ—Ä–≤–∞–ª —ñ—Å—Ç–æ—Ä—ñ—ó."
        )
        return

    max_hour = df_hourly["ts_hour"].max()
    anchor_hour = max_hour - pd.Timedelta(hours=24)

    # –Ü—Å—Ç–æ—Ä—ñ—è –¥–æ anchor_hour (–≤–∫–ª—é—á–Ω–æ)
    df_history = df_hourly[df_hourly["ts_hour"] <= anchor_hour].copy()

    # –§–∞–∫—Ç –Ω–∞ 24 –≥–æ–¥–∏–Ω–∏ –ø—ñ—Å–ª—è anchor_hour
    df_future_true = df_hourly[
        (df_hourly["ts_hour"] > anchor_hour)
        & (df_hourly["ts_hour"] <= anchor_hour + pd.Timedelta(hours=24))
    ].copy()

    if len(df_future_true) < 1:
        st.warning(
            "–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –¥–∞–Ω—ñ –ø—ñ—Å–ª—è '–≤—á–æ—Ä–∞' –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏ backtest'—É. "
            "–ú–æ–∂–ª–∏–≤–æ, —ñ—Å—Ç–æ—Ä—ñ—è —â–µ –Ω–µ –ø–æ–≤–Ω–∞."
        )
        return

    # ---------- BASELINE –í–ê–†–Ü–ê–ù–¢ (—è–∫ –±—É–≤) ----------
    if model_choice == "Baseline":
        hist_for_model = df_history.sort_values("ts_hour").copy()
        hist_for_model["ts"] = hist_for_model["ts_hour"]

        try:
            df_forecast, _ = naive_constant_forecast(
                history=hist_for_model,
                horizon_hours=len(df_future_true),
            )
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–æ–±—É–¥–æ–≤–∏ baseline-–ø—Ä–æ–≥–Ω–æ–∑—É: {e}")
            return

        model_name = "Baseline (naive constant)"

    # ---------- LSTM: teacher forcing 1-step backtest –Ω–∞ '–≤—á–æ—Ä–∞' ----------
    elif model_choice == "LSTM":
        try:
            # –≤–∞–Ω—Ç–∞–∂–∏–º–æ –º–æ–¥–µ–ª—å + scaler + —Å–ø–∏—Å–æ–∫ —Ñ—ñ—á
            model, scaler, feature_cols, target_col_idx, cfg = load_lstm_checkpoint(
                selected_coin_id, vs_currency
            )
        except FileNotFoundError:
            st.error(
                "–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–±–µ—Ä–µ–∂–µ–Ω—É LSTM-–º–æ–¥–µ–ª—å –¥–ª—è —Ü—ñ—î—ó –º–æ–Ω–µ—Ç–∏.\n\n"
                "–°–ø–æ—á–∞—Ç–∫—É –Ω–∞—Ç—Ä–µ–Ω—É–π —ó—ó –∫–æ–º–∞–Ω–¥–æ—é:\n\n"
                f"`python -m jobs.train_lstm --coin_id {selected_coin_id}`"
            )
            return
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ LSTM-–º–æ–¥–µ–ª—ñ: {e}")
            return

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        model.eval()

        # –î–ª—è —Ñ—ñ—á: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ts_hour —è–∫ –µ—Ç–∞–ª–æ–Ω–Ω–∏–π —á–∞—Å
        df_feat_input = df_hourly.copy()
        df_feat_input["ts"] = df_feat_input["ts_hour"]

        df_feat = build_feature_frame(df_feat_input)

        # df_model: —Ç—ñ–ª—å–∫–∏ ts + —Ç—ñ —Ñ—ñ—á—ñ, –Ω–∞ —è–∫–∏—Ö –Ω–∞–≤—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å
        missing = [c for c in feature_cols if c not in df_feat.columns]
        if missing:
            st.error(
                "–í –ø–æ—Ç–æ—á–Ω–æ–º—É —Ñ—Ä–µ–π–º—ñ —Ñ—ñ—á –Ω–µ –≤–∏—Å—Ç–∞—á–∞—î –∫–æ–ª–æ–Ω–æ–∫, "
                "–Ω–∞ —è–∫–∏—Ö –Ω–∞–≤—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å:\n\n"
                + ", ".join(missing)
            )
            return

        df_model = df_feat[["ts"] + feature_cols].copy()
        df_model = df_model.dropna(subset=feature_cols).reset_index(drop=True)

        if len(df_model) <= cfg.window_size + 1:
            st.error(
                f"–ó–∞–º–∞–ª–æ –¥–∞–Ω–∏—Ö –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏ –≤—ñ–∫–æ–Ω: {len(df_model)} —Ä—è–¥–∫—ñ–≤ –ø—ñ—Å–ª—è dropna, "
                f"–ø–æ—Ç—Ä—ñ–±–Ω–æ —Ö–æ—á–∞ –± window_size={cfg.window_size}."
            )
            return

        # –ú–∞—Å—à—Ç–∞–±—É—î–º–æ –≤—Å—ñ —Ñ—ñ—á—ñ —Ç–∏–º —Å–∞–º–∏–º scaler'–æ–º, —â–æ –±—É–≤ –Ω–∞ train
        values = df_model[feature_cols].values.astype(np.float32)
        scaled_all = scaler.transform(values)

        # –°—Ç–≤–æ—Ä—é—î–º–æ –º–∞–ø—É ts -> —ñ–Ω–¥–µ–∫—Å —É df_model
        ts_series = df_model["ts"]
        ts_to_idx = {ts: idx for idx, ts in enumerate(ts_series)}

        # –¶—ñ–ª—å–æ–≤—ñ —Ç–æ—á–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑—É: (anchor, anchor + 24h], –∑ –∫—Ä–æ–∫–æ–º 1 –≥–æ–¥–∏–Ω–∞
        ts_start = anchor_hour + pd.Timedelta(hours=1)   # anchor+1
        ts_end = anchor_hour + pd.Timedelta(hours=len(df_future_true))

        target_ts_list = []
        target_indices = []

        for ts in ts_series:
            if ts_start <= ts <= ts_end:
                idx = ts_to_idx[ts]
                if idx >= cfg.window_size:
                    target_ts_list.append(ts)
                    target_indices.append(idx)

        if not target_indices:
            st.error(
                "–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ —Ç–æ—á–æ–∫ –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏ –≤—ñ–∫–æ–Ω LSTM "
                "–Ω–∞ '–≤—á–æ—Ä–∞—à–Ω—ñ–π' –¥–æ–±—ñ. –ú–æ–∂–ª–∏–≤–æ, –∑–∞–º–∞–ª–æ –¥–∞–Ω–∏—Ö –ø—ñ—Å–ª—è dropna."
            )
            return

        # One-step ahead –ø—Ä–æ–≥–Ω–æ–∑–∏ –∑ teacher forcing:
        # –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ t_pred –±–µ—Ä–µ–º–æ —Ä–µ–∞–ª—å–Ω–µ –≤—ñ–∫–Ω–æ [t_pred-window_size .. t_pred-1]
        preds_scaled = []

        with torch.no_grad():
            for idx in target_indices:
                window_scaled = scaled_all[idx - cfg.window_size : idx, :]  # (W, F)
                x = torch.tensor(
                    window_scaled[None, :, :],
                    dtype=torch.float32,
                    device=device,
                )
                y_scaled = model(x).cpu().numpy()[0, 0]
                preds_scaled.append(y_scaled)

        preds_scaled_arr = np.array(preds_scaled, dtype=np.float32)

        # –Ü–Ω–≤–µ—Ä—Å—ñ—è –º–∞—Å—à—Ç–∞–±—É –¥–ª—è —Ç–∞—Ä–≥–µ—Ç–∞
        y_pred = _inverse_scale_target(
            scaler,
            feature_cols,
            target_col_idx,
            preds_scaled_arr,
        )

        # –†–µ–∞–ª—å–Ω—ñ —Ü—ñ–Ω–∏ (—Ç–∞—Ä–≥–µ—Ç) –Ω–∞ —Ü—ñ —Å–∞–º—ñ –º–æ–º–µ–Ω—Ç–∏ —á–∞—Å—É
        y_true = (
            df_model.loc[target_indices, cfg.target_col]
            .to_numpy(dtype=float)
        )

        df_forecast = pd.DataFrame(
            {
                "ts": target_ts_list,
                "y_pred": y_pred,
            }
        )

        # –î–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ –º–µ—Ä–¥–∂—É –∑ df_future_true –ø—Ä–∞—Ü—é—î–º–æ —á–µ—Ä–µ–∑ ts_hour
        df_forecast["ts_hour"] = df_forecast["ts"].dt.floor("h")

        model_name = "LSTM"

    # ---------- GRU: teacher forcing 1-step backtest ----------
    elif model_choice == "GRU":
        try:
            model, scaler, feature_cols, target_col_idx, cfg = load_gru_checkpoint(
                selected_coin_id, vs_currency
            )
        except FileNotFoundError:
            st.error(
                "–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–±–µ—Ä–µ–∂–µ–Ω—É GRU-–º–æ–¥–µ–ª—å –¥–ª—è —Ü—ñ—î—ó –º–æ–Ω–µ—Ç–∏.\n\n"
                "–°–ø–æ—á–∞—Ç–∫—É –Ω–∞—Ç—Ä–µ–Ω—É–π —ó—ó –∫–æ–º–∞–Ω–¥–æ—é:\n\n"
                f"`python -m jobs.train_gru --coin_id {selected_coin_id}`"
            )
            return
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ GRU-–º–æ–¥–µ–ª—ñ: {e}")
            return

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        model.eval()

        df_feat_input = df_hourly.copy()
        df_feat_input["ts"] = df_feat_input["ts_hour"]
        df_feat = build_feature_frame(df_feat_input)

        missing = [c for c in feature_cols if c not in df_feat.columns]
        if missing:
            st.error(
                "–í –ø–æ—Ç–æ—á–Ω–æ–º—É —Ñ—Ä–µ–π–º—ñ —Ñ—ñ—á –Ω–µ –≤–∏—Å—Ç–∞—á–∞—î –∫–æ–ª–æ–Ω–æ–∫, "
                "–Ω–∞ —è–∫–∏—Ö –Ω–∞–≤—á–∞–ª–∞—Å—å GRU:\n\n" + ", ".join(missing)
            )
            return

        df_model = df_feat[["ts"] + feature_cols].dropna().reset_index(drop=True)

        values = df_model[feature_cols].values.astype(np.float32)
        scaled_all = scaler.transform(values)

        ts_series = df_model["ts"]
        ts_to_idx = {ts: idx for idx, ts in enumerate(ts_series)}

        ts_start = anchor_hour + pd.Timedelta(hours=1)
        ts_end = anchor_hour + pd.Timedelta(hours=len(df_future_true))

        target_ts_list = []
        target_indices = []

        for ts in ts_series:
            if ts_start <= ts <= ts_end:
                idx = ts_to_idx[ts]
                if idx >= cfg.window_size:
                    target_ts_list.append(ts)
                    target_indices.append(idx)

        preds_scaled = []

        with torch.no_grad():
            for idx in target_indices:
                window_scaled = scaled_all[idx - cfg.window_size : idx, :]
                x = torch.tensor(
                    window_scaled[None, :, :], dtype=torch.float32, device=device
                )
                y_scaled = model(x).cpu().numpy()[0, 0]
                preds_scaled.append(y_scaled)

        preds_scaled_arr = np.array(preds_scaled, dtype=np.float32)

        y_pred = _inverse_scale_target(
            scaler, feature_cols, target_col_idx, preds_scaled_arr
        )

        y_true = df_model.loc[target_indices, cfg.target_col].to_numpy(float)

        df_forecast = pd.DataFrame(
            {"ts": target_ts_list, "y_pred": y_pred}
        )
        df_forecast["ts_hour"] = df_forecast["ts"].dt.floor("h")

        model_name = "GRU"


    # ---------- –°–ø—ñ–ª—å–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞: –º–µ—Ç—Ä–∏–∫–∏, –≥—Ä–∞—Ñ—ñ–∫, —Ç–∞–±–ª–∏—Ü—è ----------

    # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ —á–∞—Å —É –ø—Ä–æ–≥–Ω–æ–∑—ñ —Ç–∞ –æ–± º—î–¥–Ω—É—î–º–æ –ø–æ ts_hour
    if model_choice == "Baseline":
        df_forecast = df_forecast.copy()
        df_forecast["ts_hour"] = df_forecast["ts"].dt.floor("h")

    df_merged = pd.merge(
        df_future_true[["ts_hour", "price"]],
        df_forecast[["ts_hour", "y_pred"]],
        on="ts_hour",
        how="inner",
    )

    if df_merged.empty:
        st.warning(
            "–ù–µ –≤–¥–∞–ª–æ—Å—è –∑—ñ—Å—Ç–∞–≤–∏—Ç–∏ —Ñ–∞–∫—Ç–∏—á–Ω—ñ —Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –ø–æ –≥–æ–¥–∏–Ω–∞—Ö. "
            "–ü–µ—Ä–µ–≤—ñ—Ä, —á–∏ –¥–∞–Ω—ñ –º–∞—é—Ç—å –ø–æ–≥–æ–¥–∏–Ω–Ω—É —á–∞—Å—Ç–æ—Ç—É."
        )
        return

    # –ú–µ—Ç—Ä–∏–∫–∏
    y_true_merge = df_merged["price"]
    y_pred_merge = df_merged["y_pred"]

    mae = (y_true_merge - y_pred_merge).abs().mean()
    rmse = ((y_true_merge - y_pred_merge) ** 2).mean() ** 0.5

    st.subheader(f"Metrics for {model_name} on {selected_label}")
    st.write(
        f"**MAE:** {mae:.4f} {vs_currency.upper()}  \n"
        f"**RMSE:** {rmse:.4f} {vs_currency.upper()}"
    )

    # –ì—Ä–∞—Ñ—ñ–∫
    ctx_hours = 24
    ts_min_plot = anchor_hour - pd.Timedelta(hours=ctx_hours)

    df_plot_hist = df_hourly[
        (df_hourly["ts_hour"] >= ts_min_plot) & (df_hourly["ts_hour"] <= anchor_hour)
    ].copy()
    df_plot_hist["series"] = "History (Real)"
    df_plot_hist["ts_plot"] = df_plot_hist["ts_hour"]

    df_plot_future = df_future_true.copy()
    df_plot_future["series"] = "Future (Real)"
    df_plot_future["ts_plot"] = df_plot_future["ts_hour"]

    df_plot_forecast = df_forecast.copy()
    df_plot_forecast["series"] = f"Forecast ({model_name})"
    df_plot_forecast["ts_plot"] = df_plot_forecast["ts_hour"]
    df_plot_forecast = df_plot_forecast.rename(columns={"y_pred": "price"})

    df_plot_actual = pd.concat(
        [
            df_plot_hist[["ts_plot", "price", "series"]],
            df_plot_future[["ts_plot", "price", "series"]],
        ],
        ignore_index=True,
    )

    df_plot_all = pd.concat(
        [
            df_plot_actual,
            df_plot_forecast[["ts_plot", "price", "series"]],
        ],
        ignore_index=True,
    )

    st.subheader(f"History and yesterday's forecast ({model_name})")

    fig = px.line(
        df_plot_all,
        x="ts_plot",
        y="price",
        color="series",
        labels={
            "ts_plot": "Time",
            "price": f"Price ({vs_currency.upper()})",
            "series": "Series",
        },
    )
    fig.update_layout(height=500)

    st.plotly_chart(fig, width="stretch")

    with st.expander("Yesterday's forecast table"):
        st.dataframe(
            df_merged.sort_values("ts_hour"),
            width="stretch",
            height=400,
        )


