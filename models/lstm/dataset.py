# models/lstm/dataset.py

from typing import List, Tuple

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import torch
from torch.utils.data import Dataset, DataLoader

from features.transform import build_feature_frame
from models.lstm.config import LSTMConfig


class SequenceDataset(Dataset):
    def __init__(
        self,
        data_scaled: np.ndarray,
        window_size: int,
        target_col_idx: int,
    ) -> None:
        """
        data_scaled: (N, num_features) ‚Äî –≤–∂–µ –≤—ñ–¥–º–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω–∏–π –º–∞—Å–∏–≤
        window_size: –¥–æ–≤–∂–∏–Ω–∞ –≤—ñ–∫–Ω–∞
        target_col_idx: —ñ–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏-—Ü—ñ–ª—ñ –≤ data_scaled
        """
        self.data_scaled = data_scaled
        self.window_size = window_size
        self.target_col_idx = target_col_idx

    def __len__(self) -> int:
        # –æ—Å—Ç–∞–Ω–Ω—ñ–π y ‚Äî –Ω–∞ –ø–æ–∑–∏—Ü—ñ—ó i, –¥–µ i = len - 1
        # –ø–µ—Ä—à–∏–π –¥–æ—Å—Ç—É–ø–Ω–∏–π i = window_size
        return len(self.data_scaled) - self.window_size

    def __getitem__(self, idx: int):
        x_start = idx
        x_end = idx + self.window_size
        y_idx = x_end  # next step after window

        x = self.data_scaled[x_start:x_end, :]   # (window_size, num_features)
        y = self.data_scaled[y_idx, self.target_col_idx]  # scalar

        x_tensor = torch.tensor(x, dtype=torch.float32)
        y_tensor = torch.tensor([y], dtype=torch.float32)  # (1,)

        return x_tensor, y_tensor


def build_model_frame(df_raw: pd.DataFrame) -> pd.DataFrame:
    """
    –°—Ç–≤–æ—Ä—é—î df_model –¥–ª—è –º–æ–¥–µ–ª—ñ: price + —á–∏—Å–ª–æ–≤—ñ —Ñ—ñ—á—ñ –∑ build_feature_frame.

    –í–ê–ñ–õ–ò–í–û:
    - –±–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ —á–∏—Å–ª–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ (float/int),
    - 'price' —Å—Ç–∞–≤–∏–º–æ –ø–µ—Ä—à–æ—é,
    - —ñ–≥–Ω–æ—Ä—É—î–º–æ –±—É–¥—å-—è–∫—ñ string-–ø–æ–ª—è (—Ç–∏–ø—É coin_id, symbol, vs_currency).
    """
    df_feat = build_feature_frame(df_raw)

    # –í–∏–±–∏—Ä–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —á–∏—Å–ª–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏
    numeric_cols = df_feat.select_dtypes(include=["number", "float", "int"]).columns.tolist()

    # 'ts' ‚Äî –Ω–µ —Ñ—ñ—á–∞, —Ü—é –∫–æ–ª–æ–Ω–∫—É —Ç—Ä–∏–º–∞—î–º–æ –æ–∫—Ä–µ–º–æ
    numeric_cols = [c for c in numeric_cols if c != "ts"]

    if "price" not in numeric_cols:
        raise ValueError("–û—á—ñ–∫—É—î—Ç—å—Å—è –∫–æ–ª–æ–Ω–∫–∞ 'price' —É —Ñ—Ä–µ–π–º—ñ –∑ —Ñ—ñ—á–∞–º–∏ (numeric_cols).")

    # price —Å–ø–æ—á–∞—Ç–∫—É, –ø–æ—Ç—ñ–º —Ä–µ—à—Ç–∞ —á–∏—Å–ª–æ–≤–∏—Ö —Ñ—ñ—á
    other_cols = [c for c in numeric_cols if c != "price"]
    ordered_cols = ["price"] + other_cols

    df_model = df_feat[["ts"] + ordered_cols].copy()
    return df_model



def prepare_datasets_and_scaler(
    df_raw: pd.DataFrame,
    config: LSTMConfig,
) -> Tuple[
    DataLoader, DataLoader, MinMaxScaler, List[str], int, np.ndarray, np.ndarray
]:
    """
    –ì–æ—Ç—É—î train/test DataLoader'–∏, —Å–∫–µ–π–ª–µ—Ä —ñ —Å–ª—É–∂–±–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é.

    –ü–æ–≤–µ—Ä—Ç–∞—î:
    - train_loader
    - test_loader
    - scaler (MinMaxScaler –ø–æ –≤—Å—ñ—Ö —Ñ—ñ—á–∞—Ö)
    - feature_cols (—Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –±–µ–∑ ts)
    - target_col_idx (—ñ–Ω–¥–µ–∫—Å 'price' –≤ —Ü–∏—Ö —Ñ—ñ—á–∞—Ö)
    - train_scaled (–º–∞—Å–∏–≤ –¥–ª—è –º–æ–∂–ª–∏–≤–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É)
    - test_scaled (–º–∞—Å–∏–≤ –¥–ª—è –º–æ–∂–ª–∏–≤–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É)
    """
    df_model = build_model_frame(df_raw)

    # –ë–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ —Ñ—ñ—á—ñ (–±–µ–∑ ts)
    feature_cols = [c for c in df_model.columns if c != "ts"]
    target_col_idx = feature_cols.index(config.target_col)

    # üî¥ –ö—Ä–∏—Ç–∏—á–Ω–æ: —á–∏—Å—Ç–∏–º–æ NaN –ø–µ—Ä–µ–¥ —Å–∫–µ–π–ª—ñ–Ω–≥–æ–º
    df_model_clean = df_model.dropna(subset=feature_cols).reset_index(drop=True)

    if len(df_model_clean) <= config.window_size + 1:
        raise RuntimeError(
            f"–ó–∞–º–∞–ª–æ –¥–∞–Ω–∏—Ö –ø—ñ—Å–ª—è dropna: {len(df_model_clean)} —Ä—è–¥–∫—ñ–≤, "
            f"–∞ window_size={config.window_size}. "
            "–°–ø—Ä–æ–±—É–π –∞–±–æ –∑–º–µ–Ω—à–∏—Ç–∏ window_size, –∞–±–æ –∑–±—ñ–ª—å—à–∏—Ç–∏ —ñ—Å—Ç–æ—Ä—ñ—é."
        )

    values = df_model_clean[feature_cols].values.astype(np.float32)

    n_total = len(df_model_clean)
    split_idx = int(n_total * config.train_ratio)

    if split_idx <= config.window_size:
        raise RuntimeError(
            f"split_idx={split_idx} <= window_size={config.window_size}. "
            "–ó–±—ñ–ª—å—à—Ç–µ –æ–±—Å—è–≥ –¥–∞–Ω–∏—Ö –∞–±–æ –∑–º—ñ–Ω—ñ—Ç—å train_ratio/window_size."
        )

    # –Ø–∫ —É Colab:
    # train = [0 : split_idx]
    # test  = [split_idx - window : end] (–∑ –Ω–∞—Ö–ª—å–æ—Å—Ç–æ–º)
    train_values = values[:split_idx]
    test_values = values[split_idx - config.window_size :]

    scaler = MinMaxScaler()
    train_scaled = scaler.fit_transform(train_values)
    test_scaled = scaler.transform(test_values)

    train_dataset = SequenceDataset(
        train_scaled,
        window_size=config.window_size,
        target_col_idx=target_col_idx,
    )
    test_dataset = SequenceDataset(
        test_scaled,
        window_size=config.window_size,
        target_col_idx=target_col_idx,
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=config.batch_size,
        shuffle=True,
        drop_last=True,
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=config.batch_size,
        shuffle=False,
        drop_last=False,
    )

    return (
        train_loader,
        test_loader,
        scaler,
        feature_cols,
        target_col_idx,
        train_scaled,
        test_scaled,
    )

